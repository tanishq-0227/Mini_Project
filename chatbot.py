import json
import os
import re
from langdetect import detect, LangDetectException

# Available languages
LANGUAGES = {
    "en": "English",
    "hi": "Hindi",
    "bn": "Bengali",
    "ur": "Urdu",
    "pa": "Punjabi"
}

# Default language
DEFAULT_LANGUAGE = "en"

# Load law data for all languages
law_data = {}
for lang in LANGUAGES.keys():
    try:
        # Load IPC data for this language
        ipc_path = f"lawdata/ipc_sec_{lang}.json"
        if os.path.exists(ipc_path):
            with open(ipc_path, "r", encoding="utf-8") as f:
                ipc_data = json.load(f)
        else:
            # Fallback to English if language file doesn't exist
            with open("lawdata/ipc_sec.json", "r", encoding="utf-8") as f:
                ipc_data = json.load(f)
        
        # Load CrPC data for this language
        crpc_path = f"lawdata/crpc_sec_{lang}.json"
        if os.path.exists(crpc_path):
            with open(crpc_path, "r", encoding="utf-8") as f:
                crpc_data = json.load(f)
        else:
            # Fallback to English if language file doesn't exist
            with open("lawdata/crpc_sec.json", "r", encoding="utf-8") as f:
                crpc_data = json.load(f)
        
        # Combine both into one lookup for this language
        law_data[lang] = {**ipc_data, **crpc_data}
    except Exception as e:
        print(f"Error loading data for language {lang}: {e}")
        # Ensure we have at least English data
        if lang == "en":
            with open("lawdata/ipc_sec.json", "r", encoding="utf-8") as f:
                ipc_data = json.load(f)
            with open("lawdata/crpc_sec.json", "r", encoding="utf-8") as f:
                crpc_data = json.load(f)
            law_data["en"] = {**ipc_data, **crpc_data}

def detect_language(text):
    """Detect the language of the input text"""
    try:
        lang_code = detect(text)
        # Map detected language to our supported languages
        if lang_code == 'hi' or lang_code == 'ne':
            return 'hi'  # Hindi
        elif lang_code == 'bn':
            return 'bn'  # Bengali
        elif lang_code == 'ur':
            return 'ur'  # Urdu
        elif lang_code == 'pa':
            return 'pa'  # Punjabi
        else:
            return 'en'  # Default to English
    except LangDetectException:
        return 'en'  # Default to English if detection fails

def get_lawbot_response(user_input, lang=None):
    """Get response from LawBot in the appropriate language"""
    user_input = user_input.lower()
    
    # Detect language if not specified
    if not lang:
        detected_lang = detect_language(user_input)
    else:
        detected_lang = lang
    
    # Fallback to English if the detected language is not supported
    if detected_lang not in law_data:
        detected_lang = DEFAULT_LANGUAGE
    
    # Get language-specific responses
    responses = {
        "en": {
            "not_found": "тЭМ Sorry, I couldn't match your issue with a specific law. Please rephrase your question.",
            "section": "ЁЯУШ Section",
            "summary": "ЁЯФН Summary",
            "steps": "ЁЯУЭ Steps to Take"
        },
        "hi": {
            "not_found": "тЭМ рдХреНрд╖рдорд╛ рдХрд░реЗрдВ, рдореИрдВ рдЖрдкрдХреЗ рдореБрджреНрджреЗ рдХреЛ рдХрд┐рд╕реА рд╡рд┐рд╢рд┐рд╖реНрдЯ рдХрд╛рдиреВрди рд╕реЗ рдореЗрд▓ рдирд╣реАрдВ рдХрд░ рд╕рдХрд╛ред рдХреГрдкрдпрд╛ рдЕрдкрдирд╛ рдкреНрд░рд╢реНрди рдлрд┐рд░ рд╕реЗ рдмрддрд╛рдПрдВред",
            "section": "ЁЯУШ рдзрд╛рд░рд╛",
            "summary": "ЁЯФН рд╕рд╛рд░рд╛рдВрд╢",
            "steps": "ЁЯУЭ рдХрд╛рд░реНрд░рд╡рд╛рдИ рдХреЗ рдЪрд░рдг"
        },
        "bn": {
            "not_found": "тЭМ ржжрзБржГржЦрж┐ржд, ржЖржорж┐ ржЖржкржирж╛рж░ рж╕ржорж╕рзНржпрж╛ржЯрж┐ржХрзЗ ржХрзЛржиржУ ржирж┐рж░рзНржжрж┐рж╖рзНржЯ ржЖржЗржирзЗрж░ рж╕рж╛ржерзЗ ржорзЗрж▓рж╛рждрзЗ ржкрж╛рж░рж┐ржирж┐ред ржЕржирзБржЧрзНрж░рж╣ ржХрж░рзЗ ржЖржкржирж╛рж░ ржкрзНрж░рж╢рзНржиржЯрж┐ ржкрзБржирж░рж╛ржпрж╝ ржмрж▓рзБржиред",
            "section": "ЁЯУШ ржзрж╛рж░рж╛",
            "summary": "ЁЯФН рж╕рж╛рж░рж╛ржВрж╢",
            "steps": "ЁЯУЭ ржкржжржХрзНрж╖рзЗржк ржирж┐рждрзЗ"
        },
        "ur": {
            "not_found": "тЭМ ┘Е╪╣╪░╪▒╪к╪М ┘Е█М┌║ ╪в┘╛ ┌й█Т ┘Е╪│╪ж┘Д█Т ┌й┘И ┌й╪│█М ┘Е╪о╪╡┘И╪╡ ┘В╪з┘Ж┘И┘Ж ╪│█Т ┘Е╪╖╪з╪и┘В╪к ┘Ж█Б█М┌║ ┌й╪▒ ╪│┌й╪з█Ф ╪и╪▒╪з█Б ┌й╪▒┘Е ╪з┘╛┘Ж╪з ╪│┘И╪з┘Д ╪п┘И╪и╪з╪▒█Б ╪и█М╪з┘Ж ┌й╪▒█М┌║█Ф",
            "section": "ЁЯУШ ╪│█М┌й╪┤┘Ж",
            "summary": "ЁЯФН ╪о┘Д╪з╪╡█Б",
            "steps": "ЁЯУЭ ╪з┘В╪п╪з┘Е╪з╪к"
        },
        "pa": {
            "not_found": "тЭМ риорйБриЖрил риХри░риири╛, риорйИриВ ридрйБри╣ри╛рибрйЗ риорйБрй▒рижрйЗ риирйВрй░ риХри┐ри╕рйЗ риЦри╛ри╕ риХри╛риирйВрй░рии риири╛ри▓ риорйЗри▓ риири╣рйАриВ риХри░ ри╕риХри┐риЖред риХри┐ри░рикри╛ риХри░риХрйЗ риЖрикригри╛ ри╕ри╡ри╛ри▓ рижрйБримри╛ри░ри╛ риХри╣рйЛред",
            "section": "ЁЯУШ ри╕рйИриХри╕ри╝рии",
            "summary": "ЁЯФН ри╕ри╛ри░",
            "steps": "ЁЯУЭ риХрижрио риЪрйБрй▒риХриг ри▓риИ"
        }
    }
    
    # Search for matching keywords in the detected language
    for section, info in law_data[detected_lang].items():
        for keyword in info.get("keywords", []):
            if all(word in user_input for word in keyword.split()):
                response_text = f"{responses[detected_lang]['section']}: {section} - {info['title']}\n\n"
                response_text += f"{responses[detected_lang]['summary']}: {info['summary']}\n\n"
                response_text += f"{responses[detected_lang]['steps']}:\n"
                for i, step in enumerate(info['steps'], 1):
                    response_text += f"{i}. {step}\n"
                return {
                    "text": response_text,
                    "detected_language": detected_lang
                }
    
    # If no match in detected language, try English as fallback
    if detected_lang != DEFAULT_LANGUAGE:
        for section, info in law_data[DEFAULT_LANGUAGE].items():
            for keyword in info.get("keywords", []):
                if all(word in user_input for word in keyword.split()):
                    response_text = f"{responses[detected_lang]['section']}: {section} - {info['title']}\n\n"
                    response_text += f"{responses[detected_lang]['summary']}: {info['summary']}\n\n"
                    response_text += f"{responses[detected_lang]['steps']}:\n"
                    for i, step in enumerate(info['steps'], 1):
                        response_text += f"{i}. {step}\n"
                    return {
                        "text": response_text,
                        "detected_language": detected_lang
                    }
    
    return {
        "text": responses[detected_lang]["not_found"],
        "detected_language": detected_lang
    }
